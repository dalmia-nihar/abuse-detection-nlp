{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/NiaVivek/anaconda/lib/python3.5/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk, re, string\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sklearn.metrics as metrics\n",
    "import itertools\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import re, collections\n",
    "from nltk.corpus import words as w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the csv file and make a dataframe.\n",
    "- For training: Randomize and Divide it into 80:20 partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_Dataset(run=\"train\"):\n",
    "    df = pd.read_csv(\"train.csv\")\n",
    "    df = df[df[\"Comment\"].notnull()]\n",
    "    df.apply(np.random.permutation)\n",
    "    if run==\"train\":\n",
    "        df_train = df[:round(0.8*len(df))]\n",
    "        df_test = df[round(0.8*len(df)):]\n",
    "    elif run==\"test\":\n",
    "        df_train = df\n",
    "        df_test = pd.read_csv(\"test_with_solutions_2.csv\")\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function takes a text and does the following to return the tokens:\n",
    "* Use nltk's TweetTokenizer to get tokens\n",
    "* Use wordNetLemmatizer for lemmatization\n",
    "* Use porterStemmer to stem the resulting tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def words(text):\n",
    "    return re.findall('[a-z]+', text.lower())\n",
    "\n",
    "def train(features):\n",
    "    model = collections.defaultdict(lambda: 1)\n",
    "    for f in features:\n",
    "        model[f] += 1   \n",
    "    return model\n",
    "\n",
    "with open(\"big.txt\", \"r\") as big:\n",
    "    word_corpus = big.read()\n",
    "for word in w.words():\n",
    "    word_corpus += word\n",
    "    \n",
    "\n",
    "NWORDS = train(words(word_corpus))\n",
    "with open(\"list_of_abuses.txt\", \"r\") as abuse_list:\n",
    "    abuses = abuse_list.read().split()\n",
    "    for abuse in abuses:\n",
    "        NWORDS[abuse] = 100\n",
    "\n",
    "alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
    "\n",
    "def edits1(word):\n",
    "#     print(word)\n",
    "    s = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "    deletes    = [a + b[1:] for a, b in s if b]\n",
    "    transposes = [a + b[1] + b[0] + b[2:] for a, b in s if len(b)>1]\n",
    "    replaces   = [a + c + b[1:] for a, b in s for c in alphabet if b]\n",
    "    inserts    = [a + c + b     for a, b in s for c in alphabet]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def known_edits2(word):\n",
    "    return set(e2 for e1 in edits1(word) for e2 in edits1(e1) if e2 in NWORDS)\n",
    "\n",
    "def known(words):\n",
    "    try:\n",
    "        return [int(w) for w in words] #to take care of purely numeric words\n",
    "    except:\n",
    "        return set(w for w in words if w.lower() in NWORDS)\n",
    "\n",
    "def correct(word):\n",
    "    if word[0] not in alphabet: \n",
    "        return word\n",
    "    else:\n",
    "        word = re.sub(r'(.)\\1+', r'\\1\\1', word)\n",
    "        candidates = known([word]) or known(edits1(word)) or known_edits2(word) or [word]\n",
    "        return max(candidates, key=NWORDS.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emoticons_str = r\"\"\"\n",
    "    (?:\n",
    "        [:=;] # Eyes\n",
    "        [oO\\-]? # Nose (optional)\n",
    "        [D\\)\\]\\(\\]/\\\\OpP] # Mouth\n",
    "    )\"\"\"\n",
    " \n",
    "regex_str = [\n",
    "    emoticons_str,\n",
    "    r'<[^>]+>', # HTML tags\n",
    "    r'(?:@[\\w_]+)', # @-mentions\n",
    "    r\"(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)\", # hash-tags\n",
    "    r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', # URLs\n",
    " \n",
    "    r'(?:(?:\\d+,?)+(?:\\.?\\d+)?)', # numbers\n",
    "    r\"(?:[a-z][a-z'\\-_]+[a-z])\", # words with - and '\n",
    "    r'(?:[\\w!@#$%^&*]+)', # To group symbols together\n",
    "    r'(?:[\\w_]+)', # other words\n",
    "    \n",
    "    r'(?:\\S)' # anything else\n",
    "]\n",
    "    \n",
    "tokens_re = re.compile(r'('+'|'.join(regex_str)+')', re.VERBOSE | re.IGNORECASE)\n",
    "emoticon_re = re.compile(r'^'+emoticons_str+'$', re.VERBOSE | re.IGNORECASE)\n",
    " \n",
    "def tokenize(s):\n",
    "    tokens = tokens_re.findall(s)\n",
    "    for i in range(len(tokens)):\n",
    "        clean_token = correct(tokens[i])\n",
    "        tokens[i] = clean_token\n",
    "    return tokens\n",
    " \n",
    "def preprocess(s, lowercase=False):\n",
    "    tokens = tokenize(s)\n",
    "    if lowercase:\n",
    "        tokens = [token if emoticon_re.search(token) else token.lower() for token in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_tokens(text):\n",
    "#     tweetTokenizer = nltk.tokenize.TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "#     tokens = tweetTokenizer.tokenize(text)\n",
    "    tokens = preprocess(text, lowercase=True)\n",
    "    tokens = [nltk.WordNetLemmatizer().lemmatize(token) for token in tokens]\n",
    "    tokens= [nltk.PorterStemmer().stem(token) for token in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['your', 'a', 'retard', 'go', 'post', 'your', 'head', 'up', 'your', 'fuk']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_tokens(\"Your a retard go post your head up your f%&k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tfidf feature extraction and chi2 selection\n",
    "def feature_extraction(df_train, df_test):\n",
    "    vectorizer = TfidfVectorizer(sublinear_tf=True, ngram_range=(1,3), max_df= 0.5, analyzer= \"word\", tokenizer= build_tokens ,min_df=10,max_features=10000) #current best for max_features = 4000   \n",
    "#     count_vectorizer = CountVectorizer(analyzer=\"word\", tokenizer=build_tokens, ngram_range=(1,3), max_features=1000)\n",
    "    \n",
    "    X_train = vectorizer.fit_transform(df_train[\"Comment\"]).todense()\n",
    "    X_test = vectorizer.transform(df_test[\"Comment\"]).todense()\n",
    "\n",
    "    ch2 = SelectKBest(chi2, k = 'all') #current best for k=2300(0.8815625)\n",
    "    X_train = ch2.fit_transform(X_train, df_train.Comment)\n",
    "    X_test = ch2.transform(X_test)\n",
    "    \n",
    "    ####### Debug run #######\n",
    "    # feature_names = vectorizer.get_feature_names()\n",
    "    # feature_names = [feature_names[i] for i in ch2.get_support(indices=True)]\n",
    "    \n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# \n",
    "def classify_train(clf_type, X_train, train_category):\n",
    "    if clf_type == \"logreg\":\n",
    "#         logreg = linear_model.LogisticRegression(tol=1e-8, penalty='l2', C=4, max_iter=1000)\n",
    "        logreg = linear_model.LogisticRegression(C=8.25, max_iter=3000, tol=1e-8)\n",
    "        logreg.fit(X_train, train_category)\n",
    "        return logreg\n",
    "    elif clf_type == \"svm_rbf\":\n",
    "        clf = svm.SVC(kernel='rbf', gamma=0.8, C=1, decision_function_shape=\"ovr\", probability=True)\n",
    "        clf.fit(X_train, train_category)\n",
    "        return clf\n",
    "    elif clf_type == \"svm_linear\":\n",
    "        clf = svm.SVC(kernel = 'linear', probability = True)\n",
    "        clf.fit(X_train, train_category)\n",
    "        return clf\n",
    "    elif clf_type == \"sgd\":\n",
    "        clf = linear_model.SGDClassifier(n_iter=2000,loss = 'modified_huber', penalty = 'elasticnet', n_jobs=-1)\n",
    "        clf.fit(X_train,train_category)\n",
    "        return clf\n",
    "    elif clf_type == \"nb\":\n",
    "        clf = MultinomialNB()\n",
    "        clf.fit(X_train,train_category)\n",
    "        return clf\n",
    "    elif clf_type == \"nn\":\n",
    "        clf = MLPClassifier(solver='adam', alpha=1e-5,hidden_layer_sizes=(500,), max_iter=50000, random_state=1)\n",
    "        clf.fit(X_train,train_category)\n",
    "        return clf\n",
    "    # ensemble of different classifiers. We used a soft voting measure to combine the output\n",
    "    elif clf_type == \"ensemble\":\n",
    "        clf1 = linear_model.LogisticRegression(C=8.25, max_iter=3000, tol=1e-8)\n",
    "        clf3 = svm.SVC(kernel='rbf', gamma=0.8, C=1, decision_function_shape=\"ovr\",probability=True)\n",
    "        clf4 = linear_model.SGDClassifier(n_iter=2000,loss = 'modified_huber', penalty = 'elasticnet', n_jobs=-1)\n",
    "        clf5 = MLPClassifier(solver='adam', alpha=1e-5,hidden_layer_sizes=(500,), max_iter=50000, random_state=1)\n",
    "        eclf = VotingClassifier(estimators=[('lr',clf1),('svm_rbf',clf3), ('sgd' , clf4)], voting=\"soft\")\n",
    "        eclf = eclf.fit(X_train,train_category)\n",
    "        return eclf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This function takes a trained classifier and a set of features as input and returns the prediction of the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_predict(clf, X_test):\n",
    "    predictions = clf.predict(X_test)\n",
    "    return predictions\n",
    "\n",
    "def check_val_score(predictions, true_vals):\n",
    "    return metrics.accuracy_score(true_vals,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to plot Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, title, target_names, cmap=plt.cm.coolwarm):\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(target_names))\n",
    "    plt.xticks(tick_marks, target_names, rotation=45)\n",
    "    plt.yticks(tick_marks, target_names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline and Adding Custom features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding additional features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 custom features are added - percentage of bad words in a sentence as listed in the bad words file and the compound value from vader sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class AdditionalFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def get_feature_names(self):\n",
    "        return (['percent_bad','vader_compound'])\n",
    "    \n",
    "    def num_bad(self, df):\n",
    "        #get number of words in each sentence\n",
    "        num_words = [len(word) for word in df]\n",
    "        \n",
    "        #get percent of abusive words in each sentence\n",
    "        with open(\"list_of_abuses.txt\", \"r\") as abuse_list:\n",
    "            abuses = abuse_list.read().split()\n",
    "            num_abuses = 0\n",
    "            for abuse in abuses:\n",
    "                num_abuses += 1\n",
    "            # number of badwords in list of abuses\n",
    "            num_bad = [np.sum([word.lower().count(abuse) for abuse in abuses])\n",
    "                                                for word in df]\n",
    "            norm_bad = np.array(num_bad) / np.array(num_words, dtype=np.float)\n",
    "        return norm_bad\n",
    "    \n",
    "    def vader_helper(self, df):\n",
    "        #vader analysis\n",
    "        sid = SentimentIntensityAnalyzer()\n",
    "        vader_feature = []\n",
    "        for sentence in df:\n",
    "            ss = sid.polarity_scores(sentence)\n",
    "            vader_feature.append(ss['compound'])\n",
    "        return vader_feature\n",
    "    \n",
    "    def transform(self, df, y=None):     \n",
    "        #add both the features to an array\n",
    "        X = np.array([self.num_bad(df), self.vader_helper(df)]).T\n",
    "        #X.reshape(-1, 1) #use if only 1 feature\n",
    "        if not hasattr(self, 'scalar'):\n",
    "            self.scalar = preprocessing.StandardScaler().fit(X)\n",
    "        return self.scalar.transform(X)      \n",
    "\n",
    "    def fit(self, df, y=None):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def all_features():\n",
    "    features = []\n",
    "    custom_features = AdditionalFeatureExtractor() # this class includes my custom features\n",
    "    features.append(('custom_features', custom_features))\n",
    "\n",
    "    vect = TfidfVectorizer(sublinear_tf=True, ngram_range=(1,3), max_df= 0.5, analyzer= \"word\", tokenizer= build_tokens ,min_df=10,max_features=10000)\n",
    "    count_vect = CountVectorizer(analyzer=\"word\", tokenizer=build_tokens, ngram_range=(1,1), max_features=1000)\n",
    "    features.append(('ngram', vect))\n",
    "    features.append(('count', count_vect))\n",
    "\n",
    "    all_features = FeatureUnion(features)\n",
    "    return all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def all_classifiers():\n",
    "    clf1 = linear_model.LogisticRegression(C=8.25, max_iter=3000, tol=1e-8)\n",
    "    clf3 = svm.SVC(kernel='rbf', gamma=0.8, C=1, decision_function_shape=\"ovr\",probability=True)\n",
    "    clf4 = linear_model.SGDClassifier(n_iter=2000,loss = 'modified_huber', penalty = 'elasticnet',alpha=0.001, n_jobs=-1)\n",
    "    #clf5 = MLPClassifier(solver='adam', alpha=1e-5,hidden_layer_sizes=(500,),  max_iter=50000, random_state=1)\n",
    "    eclf = VotingClassifier(estimators=[('lr',clf1),('svm_rbf',clf3), ('sgd' , clf4)], voting=\"soft\")\n",
    "    return eclf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_clf = Pipeline([\n",
    "    ('all', all_features() ),\n",
    "    #('kbest', SelectKBest(chi2, k = 'all')),\n",
    "    ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "    ('ensemble',all_classifiers()),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing pipeline and custom features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train, df_test = load_Dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_clf.fit(df_train.Comment,df_train.Insult)\n",
    "predicted = best_clf.predict(df_test.Comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83523447401774398"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(df_test.Insult,predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.92      0.89       578\n",
      "          1       0.73      0.61      0.66       211\n",
      "\n",
      "avg / total       0.83      0.84      0.83       789\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_labels = np.sort(df_train.Insult.unique())\n",
    "lables = [str(i) for i in class_labels]\n",
    "print(classification_report(df_test.Insult, predicted, target_names=lables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing on test set - using pipeline and custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train, df_test = load_Dataset(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = best_clf.predict(df_test.Comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59451659451659455"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(df_test.Insult,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         0\n",
      "          1       1.00      0.59      0.75       693\n",
      "\n",
      "avg / total       1.00      0.59      0.75       693\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/NiaVivek/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_test.Insult, predictions, target_names=lables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAI5CAYAAACLh8G7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119f93240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nb_cm = confusion_matrix(df_test.Insult, predictions)\n",
    "plot_confusion_matrix(nb_cm, \"Confusion Matrix\", class_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train, df_test = load_Dataset()\n",
    "X_train, X_test = feature_extraction(df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11a680860>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD7CAYAAAB68m/qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a669f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "category_counts = df_train[\"Insult\"].value_counts(ascending=True)\n",
    "category_counts.plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = classify_train(\"ensemble\", X_train, df_train.Insult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.84030418251\n"
     ]
    }
   ],
   "source": [
    "predictions = classify_predict(clf, X_test)\n",
    "print(check_val_score(predictions, df_test.Insult))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.92      0.89       578\n",
      "          1       0.73      0.64      0.68       211\n",
      "\n",
      "avg / total       0.84      0.84      0.84       789\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_labels = np.sort(df_train.Insult.unique())\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "lables = [str(i) for i in class_labels]\n",
    "print(classification_report(df_test.Insult, predictions, target_names=lables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train, df_test = load_Dataset(\"test\")\n",
    "X_train, X_test = feature_extraction(df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = classify_train(\"ensemble\", X_train, df_train.Insult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.606060606061\n"
     ]
    }
   ],
   "source": [
    "predictions = classify_predict(clf, X_test)\n",
    "print(check_val_score(predictions, df_test.Insult))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         0\n",
      "          1       1.00      0.62      0.77       693\n",
      "\n",
      "avg / total       1.00      0.62      0.77       693\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/NiaVivek/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_test.Insult, predictions, target_names=lables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SOME USEFUL CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Code for stratified dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code can be used to determine the best model as there is class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_set = pd.read_csv(\"train.csv\")\n",
    "skf = StratifiedKFold(data_set.Insult,n_folds=3)\n",
    "accuracy = 0\n",
    "best_model = None\n",
    "prediction = None\n",
    "y = None\n",
    "for train_index, test_index in skf:\n",
    "    X_train, X_test = data_set.Comment[train_index], data_set.Comment[test_index]\n",
    "    y_train,y_test = data_set.Insult[train_index], data_set.Insult[test_index]\n",
    "    # Drop any resulting nan values\n",
    "    X_train.dropna(inplace=True)\n",
    "    y_train.dropna(inplace=True)\n",
    "    X_test.dropna(inplace=True)\n",
    "    y_test.dropna(inplace=True)\n",
    "    # Train model using created datasets\n",
    "    best_clf.fit(X_train, y_train)\n",
    "    print('Trained model on new train dataset.')\n",
    "    # Predict on test\n",
    "    predicted = best_clf.predict(X_test)\n",
    "    print('Accuracy on test dataset: ')\n",
    "    test_accuracy = accuracy_score(y_test,predicted)\n",
    "    print(test_accuracy)\n",
    "    \n",
    "    # Save models and accuracy so that we can use it later\n",
    "    if (test_accuracy > accuracy):\n",
    "        accuracy = test_accuracy\n",
    "        best_model = best_clf\n",
    "        prediction = predicted\n",
    "        y = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Code for hyperparameters testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use this code to determine hyperparameters for the classifiers using GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_clf_hyp = Pipeline([('vect', TfidfVectorizer(tokenizer=build_tokens,ngram_range=(1, 3)\n",
    "                                              , min_df=8\n",
    "                      ,stop_words=stopwords.words('english'),max_features=5000)),\n",
    "                     ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "                     ('clf', SGDClassifier(loss='modified_huber', penalty='elasticnet',alpha=0.0001, n_iter=10, random_state=42)), ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {'vect__ngram_range': [(1, 3)],'vect__min_df':[5,8],'tfidf__use_idf': [True],'clf__alpha': [1e-3,1e-4]\n",
    "              ,'clf__n_iter':(1000,2000),}\n",
    "gs_clf = GridSearchCV(best_clf_hyp, parameters, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs_clf = gs_clf.fit(df_train.Comment,df_train.Insult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Best score:',gs_clf.best_score_)\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
